import torch
import json
import re
import os
from tqdm import tqdm
from transformers import AutoModelForCausalLM, AutoTokenizer
from peft import PeftModel
from datasets import load_dataset

# ================= é…ç½® =================
BASE_MODEL = "/home/mac/PycharmProjects/PythonProject/yoyo/models/Qwen2.5-Coder-7B-Instruct"
LORA_PATH = "/home/mac/PycharmProjects/PythonProject/yoyo/solhint/lora/solidity_lintseq"
OUTPUT_FILE = "solutions_with_diff.json"
# =======================================

def parse_lintseq_diff(raw_output):
    """
    ã€æŒ‡æ ‡ 4 æ ¸å¿ƒé€»è¾‘ã€‘: è§£æ Diff æ ¼å¼
    è¿”å›: (is_valid_diff, clean_code)
    """
    lines = raw_output.split('\n')
    clean_lines = []
    has_diff_header = False
    valid_changes = False

    try:
        for line in lines:
            # æ£€æŸ¥æ˜¯å¦æœ‰ Diff å¤´ (@@ ... @@)
            if line.startswith('@@') and line.endswith('@@'):
                has_diff_header = True
                continue
            
            # æå–æ–°å¢è¡Œ
            if line.startswith('+'):
                clean_lines.append(line[1:]) # å»æ‰ +
                valid_changes = True
            elif line.startswith('-'):
                continue # å¿½ç•¥åˆ é™¤è¡Œ
            else:
                # æŸäº›æ¨¡å‹å¯èƒ½æ··æ‚çº¯æ–‡æœ¬ï¼Œå¦‚æœæ²¡+å·ä½†ä¹Ÿä¸æ˜¯-å·ï¼Œä¿ç•™
                clean_lines.append(line)
        
        cleaned_code = '\n'.join(clean_lines)
        
        # åˆ¤å®šæ ‡å‡†ï¼šåªè¦åŒ…å« Diff å¤´æˆ–è€…æœ‰ + å·ä¿®æ”¹ï¼Œå°±ç®—æ ¼å¼åˆæ³•
        is_valid = has_diff_header or valid_changes
        
        # å…œåº•ï¼šå¦‚æœæ¸…æ´—å‡ºæ¥æ˜¯ç©ºçš„ï¼Œè¯´æ˜è§£æå¤±è´¥
        if not cleaned_code.strip():
            is_valid = False
            
        return is_valid, cleaned_code

    except Exception:
        return False, ""

def main():
    print("ğŸš€ Loading Model...")
    tokenizer = AutoTokenizer.from_pretrained(BASE_MODEL, trust_remote_code=True)
    base_model = AutoModelForCausalLM.from_pretrained(
        BASE_MODEL, torch_dtype=torch.bfloat16, attn_implementation="sdpa", device_map="auto", trust_remote_code=True
    )
    model = PeftModel.from_pretrained(base_model, LORA_PATH)
    model.eval()

    print("ğŸ“š Loading HumanEval-Solidity...")
    dataset = load_dataset("structures-research/HumanEval-Solidity", split="test")
    # dataset = dataset.select(range(10)) # è°ƒè¯•æ—¶è§£å¼€è¿™è¡Œï¼Œåªè·‘10ä¸ª

    results = []
    diff_valid_count = 0

    print("âš¡ Start Generation...")
    for task in tqdm(dataset):
        prompt = task['prompt']
        
        # æ„é€ è¾“å…¥
        messages = [{"role": "user", "content": prompt}]
        input_text = tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)
        inputs = tokenizer([input_text], return_tensors="pt").to(model.device)

        with torch.no_grad():
            outputs = model.generate(
                **inputs, max_new_tokens=1024, temperature=0.2, top_p=0.95, do_sample=True
            )
        
        raw_output = tokenizer.batch_decode(outputs[:, inputs.input_ids.shape[1]:], skip_special_tokens=True)[0]
        
        # --- è®¡ç®— Metric 4: Diff Validity ---
        is_valid_diff, clean_code = parse_lintseq_diff(raw_output)
        if is_valid_diff:
            diff_valid_count += 1
        
        # ç®€å•çš„åå¤„ç†ï¼šå¦‚æœ clean_code é‡Œæ²¡æœ‰ promptï¼ŒæŠŠ prompt æ‹¼å›å» (ä¸ºäº†èƒ½ç¼–è¯‘)
        if "contract " not in clean_code and "function " not in clean_code:
            final_code = prompt + "\n" + clean_code
        else:
            final_code = clean_code

        results.append({
            "task_id": task['task_id'],
            "raw_output": raw_output,
            "final_code": final_code,
            "diff_valid": is_valid_diff,
            "test_code": task['test'] # ç”¨äº Pass@1
        })

    # ä¿å­˜
    with open(OUTPUT_FILE, "w") as f:
        json.dump(results, f, indent=2)

    print("\n" + "="*40)
    print(f" Metric 4: Diff Validity Rate")
    print(f"Valid Diffs: {diff_valid_count}/{len(dataset)}")
    print(f"Score: {diff_valid_count/len(dataset)*100:.2f}%")
    print("="*40)
    print(f"ç»“æœå·²ä¿å­˜åˆ° {OUTPUT_FILE}ï¼Œè¯·è¿è¡Œ step2_evaluate.py")

if __name__ == "__main__":
    main()
